{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Architecture\n",
    "![](images/architecture.PNG)\n",
    "\n",
    "In this section we will build the componenets related to development environment.As shown in the figure we will work on:\n",
    "1. Training the Model\n",
    "2. Building Feature Extractor\n",
    "3. Building APIs for connecting ML services to the world wide web. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Configuration\n",
    "\n",
    "This module involves the list of things required to start our ML model deployment.\n",
    "1. Github Account\n",
    "2. Git bash terminal\n",
    "3. Folking repository from [link]\n",
    "4. Creating Virtual Environment\n",
    "5. Installing Text Editor\n",
    "\n",
    "Below are the series of steps that can be followed to configure them.\n",
    "\n",
    "1. Create github account\n",
    "2. Install Git bash terminal from [https://git-scm.com/downloads]\n",
    "3. Go to Command propt and cofigure name and email_id\n",
    "    * git config --global user.name \"your name\"\n",
    "    * git config -- global user.email youremailaddress@x.com\n",
    "    <br>\n",
    "Check on cmd to verify config by typing:-\n",
    "    * git config user.name\n",
    "    * git config user.email\n",
    "    \n",
    "4. Folk a repository\n",
    "5. Opening Pull request to your repo instead of the original repo\n",
    "    * git remote set-url origin [link]\n",
    "6. Create a branch \n",
    "    * git checkout -b test-branch-2 \n",
    "7. Do commit\n",
    "    * git commit --allow-empty -m \"opening project\"\n",
    "8. Pull request \n",
    "    * git push origin test-branch-2\n",
    "    \n",
    "9. Creating virtual env---\n",
    "Go into the required folder\n",
    "    * python -m venv deploy\n",
    "---Check throug typing\n",
    "    * dir\n",
    "10. Activate your Virtual Environment \n",
    "    * [env_name==deploy]\\Scripts\\activate\n",
    "11. Deactivate your Virtual Environment\n",
    "    * deactivate\n",
    "12. Installing requirement files\n",
    "    * pip install -r requirements.txt\n",
    "13. Select any text editor\n",
    "    * Subime\n",
    "    * Vim\n",
    "    * Emac\n",
    "    * Pycharm\n",
    "    \n",
    "Note: In windows the pytest is very buggy.Make sure your versions are inline with what is mentioned below:\n",
    "\n",
    "1. pytest==4.0.2\n",
    "2. py==1.7.0\n",
    "3. pluggy==0.8.1\n",
    "4. attrs==19.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit-1-train_model\n",
    "\n",
    "![](images/dir1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataset for training and testing\n",
    "\n",
    "1. Download the train.csv and test.csv files from the [Kaggle Competiton link](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "2. Save train.csv and test.csv files in the datasets folder of your directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "**preprocessors.py**<br>\n",
    "    Lists all the preprocessing task involved in this model building exercise.\n",
    "    \n",
    "    * Categorical Imputer\n",
    "    * Numerical Imputer\n",
    "    * Temporal Variable estimator\n",
    "    * RareLabel Categorical Encoder\n",
    "    * Categorical Encoder\n",
    "    * Drop Unnecessary Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline\n",
    "\n",
    "One of the often reason for ML models to break in production is the reproducibility in offline and online environment.Hence, it is necessary to collate all the preprocessing tasks and create a pipeline that can be leverage both at the time of training and at the time of inference.\n",
    "\n",
    "Current Pipeline does the following tasks:\n",
    "1. Categorical Imputer\n",
    "2. Numerical Imputer\n",
    "3. Temporal Variable\n",
    "4. Rare Label Encoder\n",
    "5. Categorical Encoder\n",
    "6. Log transform\n",
    "7. Drop Features\n",
    "7. MinMax Scalar\n",
    "8. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "**train_pipeline.py**<br>\n",
    "   This module involves training the model leveraging all the modules defined above.\n",
    "   \n",
    "   Major tasks performed in this module:\n",
    "   1. Load Dataset\n",
    "   2. Train-Test Split\n",
    "   3. Trasformation on Target Variable\n",
    "   4. Running Pipeline\n",
    "   5. Saving Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running train_pipeline\n",
    "\n",
    "Run the train_pipeline which will do the following:\n",
    "\n",
    "1. Load dataset\n",
    "2. Split into train and test\n",
    "3. Do Feature Processing\n",
    "4. Train Model\n",
    "5. Save model under trained_model directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit-2-Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring in directories\n",
    "\n",
    "This is important when we are packaging and publishing our regression model.You will find the relevance as we go ahead\n",
    "![](images/dir2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility modules\n",
    "\n",
    "Our train_pipeline has been modified with restructuring our code using **data_management.py** and **config.py**\n",
    "\n",
    "1. **Data Management.py**<br>\n",
    "Lists all the utility functions required in model training.\n",
    "2. **config.py**<br>\n",
    "Configuration file with all the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition in the requirements.txt\n",
    "\n",
    "Install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition of Python Path to Environment Variables\n",
    "\n",
    "Make sure you add the regression_model parent directory to your Pythonpath\n",
    "\n",
    "Go to environment variables and add a new User Variable\n",
    "\n",
    "**Name** - PYTHONPATH <br>\n",
    "**PATH** - C:\\Users\\u6yuv\\Documents\\Courses\\dev\\ml-package\\regression_model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run train_pipeline again\n",
    "\n",
    "Rerun the training script to ensure the .pkl file is present\n",
    "\n",
    "For this , we will create a training file as shown below\n",
    "\n",
    "![](images/run_train_pipeline.png)\n",
    "\n",
    "![](images/run_train_pipeline_terminal.png)\n",
    "\n",
    "or add the syspath in the exisiting train_pipeline and run from regression_model parent directory\n",
    "![](images/run_train_pipeline_parent_code.png)\n",
    "\n",
    "![](images/run_train_pipeline_parent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tests\n",
    "\n",
    "We added a test_predict file which will test for a single prediction\n",
    "\n",
    "![](images/test_predict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tesing\n",
    "\n",
    "![](images/test1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more addition into config\n",
    "\n",
    "config file\n",
    "\n",
    "![](images/config_update.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modification in pipeline.py\n",
    "\n",
    "As now we are using config file for interacting with our ml modulde, references to variables used in pipeline has to be passed through config file.\n",
    "\n",
    "<b>change-<b> \n",
    "config.CATEGORICAL_VARS_WITH_NA\n",
    "\n",
    "![](images/pipeline_update.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessors.py\n",
    "\n",
    "In the earlier commit version , preprocessors.py was under the regression_model directory but now we are moving it under processing directory.\n",
    "\n",
    "![](images/shifting_preprocessors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation script\n",
    "\n",
    "Addition of validation script which has the necessary validation rules as our training pipleline.\n",
    "\n",
    "In our test_data we have NA values which needs to be handled before making predictions. \n",
    "\n",
    "\n",
    "![](images/validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additing validation in prediction.py\n",
    "\n",
    "Adding validation rules as our test data has NA values\n",
    "\n",
    "![](images/val_predict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding test for multiple rows\n",
    "\n",
    "![](images/test2_multiple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train pipeline again\n",
    "\n",
    "we have changed the directory structure so to make sure everything works correctly , we are running the training pipeline again.\n",
    "\n",
    "![](images/train_pipeline_again.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running test for multiple rows\n",
    "\n",
    "![](images/test_predict3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Until now , in our preprocessors.py file had a mix of both preprocessing operations and feature engineering. We will separate out the feature engineering operations from preprocessing operations to have a clear distinction between the two. It is important for the following reasons:\n",
    "\n",
    "1. In our current assignment  we are dealing with just one feature engineering step i.e. Log Transformation .However this module can be far more complex than this example for eg:\n",
    "    * Accessing a database to pick precalclulated features.\n",
    "    * Third party API call to gather information .eg - Weather\n",
    "    * A separate model to generate features that will be an input feature to our current model\n",
    "2. The features can be a very complicated section of your application and it could indeed be imported as a totally separate package with its own versioning.\n",
    "\n",
    "Hence we will be creating a sperate file **features.py** that will list all the feature engineering work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update preprocessor.py \n",
    "\n",
    "It will no longer contain Log transformation operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features.py\n",
    "\n",
    "It will contain all the operations related to feature engineering.\n",
    "\n",
    "![](images/features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update pipeline.py\n",
    "\n",
    "Things to add: \n",
    "\n",
    "1. Import features.py file\n",
    "2. Change the log transformer in the pipeline\n",
    "\n",
    "![](images/pipeline_update1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training again\n",
    "\n",
    "![](images/train_pipeline_again1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests again\n",
    "\n",
    "![](images/test_predict4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning and Logging\n",
    "\n",
    "Logging versioning and logging play a really important role in production machine learning systems.\n",
    "They're very important for reproducibility because they provide insights and information about for example which inputs went into making a given prediction and the timeframe when certain predictions were made and generally give clues to allow us to track down bugs in our code as well as meeting things like regulatory requirements and then being able to conduct audits on the sorts of machine learning predictions we're making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding version file\n",
    "\n",
    "VERSION file - 0.1.0 [MAJOR.MINOR.PATCH]\n",
    "\n",
    "![](images/version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the version file in __init__\n",
    "\n",
    "![](images/read_version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding logging config\n",
    "\n",
    "![](images/logging_config.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding logging in multiple files\n",
    "\n",
    "1. data_management.py\n",
    "\n",
    "![](images/data_management_log.png)\n",
    "\n",
    "2. train_pipeline.py\n",
    "\n",
    "3. pipeline.py \n",
    "\n",
    "4. predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add errors.py\n",
    "\n",
    "\n",
    "![](images/errors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use custom errors in features.py\n",
    "\n",
    "![](images/features_custom_error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update config.py\n",
    "\n",
    "![](images/config_update1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run train_pipeline again\n",
    "\n",
    "![](images/train_pipeline_version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test\n",
    "\n",
    "![](images/test_predict5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements.txt\n",
    "\n",
    "![](images/requirements.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup.py\n",
    "\n",
    "![](images/setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifest.in\n",
    "\n",
    "![](images/manifest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the requirments\n",
    "\n",
    "![](images/install_requirements.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the source distribution and wheel distribution\n",
    "\n",
    "![](images/run_setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the package and test it\n",
    "\n",
    "![](images/install_library.png)\n",
    "\n",
    "![](images/package_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Our Model-Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little about REST API.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "An API is an application programming interface. It is a set of rules that allow programs to talk to each other. The developer creates the API on the server and allows the client to talk to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST\n",
    "\n",
    "REST determines how the API looks like.It is a set of rules that developers follow when they create their API.One of these rules states that you should be able to get a piece of data (called a **resource**) when you link to a specific URL.\n",
    "\n",
    "Each URL is called a **request** while the data sent back to you is called a **response**.\n",
    "\n",
    "\n",
    "**JSON (JavaScript Object Notation)** a common format for sending and requesting data through a REST API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUEST\n",
    "\n",
    "Request is made up of four things:\n",
    "\n",
    "1. **The endpoint** -The endpoint (or route) is the url you request for.\n",
    "    1. **path** - determines the resource you’re requesting for. Think of it like an automatic answering machine that asks you to press 1 for a service, press 2 for another service, 3 for yet another service and so on.\n",
    "2. **The method** -The method is the type of request you send to the server. You can choose from these five types below:\n",
    "    1. **GET**   - Read a resource on a server\n",
    "    2. **POST**  - Creates a new resource on a server\n",
    "    3. **PUT and PATCH**  - Update a resource on a server\n",
    "    4. **DELETE** - Delete a resource from a server.\n",
    "3. **The headers**    - Headers are used to provide information to both the client and server.eg authentication and providing information about the body content\n",
    "4. **The data (or body)** - The data (sometimes called “body” or “message”) contains information you want to be sent to the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of Model Serving via REST API\n",
    "\n",
    "1. Serve predictions to client on the fly to multiple clients\n",
    "2. Decouple our model development from the client facing layer\n",
    "3. Potentially combine multiple models at different API endpoints\n",
    "4. Scale by adding more instances of the application behind the load balancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing API skeleton\n",
    "\n",
    "Adding ml-api folder \n",
    "![](images/api_skeleton.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding requirements.txt\n",
    "\n",
    "![](images/api_requirements.png)\n",
    "\n",
    "Install the required dependencies\n",
    "![](images/api_requirements_execute.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py\n",
    "\n",
    "Create flask app\n",
    "![](images/create_flask_app.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### controller.py\n",
    "\n",
    "The api create above interacts through an endpoint.The endpoint is defined in controller.py file\n",
    "\n",
    "![](images/controller.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run.py\n",
    "\n",
    "It is the entrypoint to start flask\n",
    "![](images/api_run.png)\n",
    "\n",
    "**Tell the flask what is the entrypoint to start the api**\n",
    "\n",
    "**Run the flask app**\n",
    "\n",
    "![](images/run_api1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the endpoint\n",
    "\n",
    "![](images/health_app.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Config and Logging\n",
    "\n",
    "Addition of the following:\n",
    "1. Config file\n",
    "2. Updation in the app.py and controller.py using config and logging\n",
    "3. testing module\n",
    "\n",
    "![](images/api_log_config.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config.py\n",
    "![](images/api_config.png)\n",
    "\n",
    "Look for multiple Config objects at the end of the file that will be used to set flask properties while creating app\n",
    "\n",
    "![](images/api_config_object.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests/conftest.py\n",
    "\n",
    "For reusability \n",
    "Read about fixtures\n",
    "\n",
    "![](images/api_fixtures.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_controller.py\n",
    "\n",
    "Passing pytest fixtures to test particular endpoint.\n",
    "![](images/test_fixtures.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update app.py and controller.py\n",
    "\n",
    "1. Added the logging mechanism as we did in regression model\n",
    "2. Configuration of the app now from the config object\n",
    "\n",
    "![](images/update_app.png)\n",
    "\n",
    "![](images/controller_update.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test\n",
    "\n",
    "![](images/api_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# api prediction_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update in controller.py\n",
    "\n",
    "Addition of predict/regression endpoint that will serve to POST request\n",
    "\n",
    "Here v1 refers to our one of the version of endpoint for serving prediction and has nothing to do with model or api version.\n",
    "\n",
    "Here we are leveraging regression model - **make prediction** utility to ensure there is just one copy of utility that is being used everywhere.It also helps to keep our api lightweight as we are taking away all the feature engineering/processing task from api.\n",
    "\n",
    "![](images/predict_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update in test_controller.py\n",
    "\n",
    "We have added **test_prediction_endpoint_returns_prediction** function for our prediction.\n",
    "\n",
    "Again we are leveraging regression model package to get the testing dataset.\n",
    "\n",
    "![](images/predict_regression_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the prediction endpoint\n",
    "\n",
    "![](images/test_controller.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the version file\n",
    "\n",
    "![](images/api_version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding endpoint for version checking- controller.py\n",
    "\n",
    "![](images/controller_version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addign test for version checking -test_controller.py\n",
    "\n",
    "![](images/test_controller_version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing test for version\n",
    "\n",
    "![](images/api_version_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the api version and model version\n",
    "\n",
    "![](images/version_check.png)\n",
    "\n",
    "![](images/version_check_browser.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. [Git CheatSheet](https://www.atlassian.com/git/tutorials/atlassian-git-cheatsheet)\n",
    "2. [Git course](https://www.pluralsight.com/courses/code-school-git-real)\n",
    "3. [Working with folks](https://stackoverflow.com/questions/25545613/how-can-i-push-to-my-fork-from-a-clone-of-the-original-repo)\n",
    "4. [Testing](https://landing.google.com/sre/sre-book/chapters/testing-reliability/)\n",
    "5. [Trunk based Development](https://trunkbaseddevelopment.com/)\n",
    "6. Fluent Python\n",
    "7. The Devops Handbook<BR>\n",
    "**PACKAGING**    \n",
    "8. [Python Packaging](https://packaging.python.org/)\n",
    "9. [Python Versioning](https://packaging.python.org/guides/single-sourcing-package-version/)\n",
    "10. [ Python Logging](https://docs.python.org/3/library/logging.html)\n",
    "9. [Python packaging and PyPI](https://www.youtube.com/watch?v=na0hQI5Ep5E)\n",
    "10. [Setuptools documentation](https://setuptools.readthedocs.io/en/latest/)\n",
    "11. [Wheel Documentation](https://wheel.readthedocs.io/en/stable/)\n",
    "12. [Pytest Documentation](https://docs.pytest.org/en/latest/)<BR>\n",
    "**REST API**\n",
    "13. [REST API Principles](https://restfulapi.net/rest-architectural-constraints/)\n",
    "14. [REST API Walkthrough](https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/)\n",
    "15. [Flask Tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)\n",
    "16. [Web Frameworks](https://github.com/vinta/awesome-python#web-frameworks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "315.823px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
